---
title: "Conclusions"
author: "Markus Knoefler"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: true
params:
  n: NA
---

```{r setup, include=FALSE}
library(knitr)
library(rgl)
library(ggplot2)
library("car")
knit_hooks$set(webgl = hook_webgl)
knitr::opts_chunk$set(echo = TRUE)
```

# Tag 1

## Daten an der Uni St.Gallen
* Polystrukturierte Daten
    + Logdaten / Service Calls
        - Koennen privacy-kritischen Inhalt haben
    + WLan-Accespoint Daten
        - Ort, Zeit, Dauer
        - Geraet / OS
        - Downloadmenge
    + KPI's der Entwicklung
        - Tickets
        - Shift left
        - Work in Progress
        - Changesets
        - Failed Builds/Tests
* Fast nur strukturierte Daten
    + Alles rund ums Studium (Addressdaten (mit Photo), Noten, Stundenplaene, Raumbelegungen, ...)

## Smart Data - LogDaten
* Hypothesen erstellen und formulieren was man gerne wissen moechte
    + Immer zum Semesterstart, werden die Applikationen in die Knie gezwungen
    + Probleme treten zyklisch auf
* Definieren welche Daten/Werte es braucht, um die Hypothesen zu beweisen
    + Datum, Zeit, Servicename (REST), aufrufende Applikation, OS, Credentials, Statuswerte des Aufrufes
* Massnahmen ergreifen
    + Beispiele koennten sein, ein Pikettdienst, gezielte efforts in Codestabilitaet/Bugfixing/Refactoring, temporaer mehr Serverpower
    
## Data mining in Wlan-Daten
* Anomaly detection
    +Kann Hinweis fuer ein kommendes Problem sein
* Association Rule Learning
    + Pruefungs- / Lernzeiten, Mensacrowd, Belegung der Lernplaetze
* Clustering
    + Evtl. legen bestimmte Benutzer- / Geraetegruppen unterschiedliche Verhalten an den Tag
* Classification
    +Navigationssystem fuer freie Plaetze zum lernen oder in der Mensa
* Regression
    + Anhand von Simulationen freie Plaetze in naher Zukunft vorschlagen
* Summarization
    + Geht meiner Meinung nach mit der Regression einher. Nur relevante Daten verwenden muessen, um dem Kunden die fuer ihn interessanten Conclusions visualisieren zu koennen

<https://en.wikipedia.org/wiki/Data_mining>

# Tag 2
Es gibt verschiedene Moeglichkeiten Daten zu lesen. Der Readbefehl haengt vom Dateityp der Quelle ab. Die bis anhing fuer uns wichtigsten sind:

* read.table("FullPath/FileName.txt")
* read.csv("FullPath/FileName.csv")
* read.xlsx("FullPath/FileName.xlsx")
* und natuerlich die load() Funktion falls die Daten im R eigenen Format vorliegen.
* weitere sind in der Dokumentation zu finden <https://www.statmethods.net/input/importingdata.html>
\newline

```{r}
load("C:/Users/mknoefler/OneDrive/Documents/BigData/R/Umfrage.rda")
```

Es ist ratsam sich anfangs jeweils einen groben Ueberblick ueber die geladenen Daten zu verschaffen. Dazu sind die Befehle **dim**, **summary**, **str** und **head** sehr hilfreich.\newline Alle Befehle in R sind online dokumentiert und koennen mit dem Fragezeichen (z.B. ?head) aufgerufen werden.
```{r}
dim(Umfrage) # gibt Auskunft ueber die Dimension der Daten
summary(Umfrage) # zeigt deskriptive Statistiken an
str(Umfrage) # zeigt die Eigenschaften (Variablen, Columns, ...) an
head(Umfrage,5) # zeigt die ersten 10 Datensaetze an
```

Im folgenden wird ein Data Frame mit verschiedenen, rein zufaelligen Werten erzeugt. Entweder wird ein Observations count via **Shiny App** als Parameter ins **RMarkdown** gegeben, ansonsten wird ein Defaultwert genommen.
```{r}
minObservations<-10
if (params$n == "NA" | params$n < minObservations) {
  observationCount<-minObservations
} else {
  observationCount<-params$n
}
ids<-seq(1,length=observationCount)
head(ids)
age<-round(runif(observationCount,min=18,max=100))
head(age)
sex<-sample(c("w","m"),size=observationCount,replace=T)
head(sex)
size<-round(runif(observationCount,min=150,max=200))
head(size)
income<-round(runif(observationCount,min=60000,max=180000))
head(income)
education<-sample(c("Grundschule","Lehre","Hochschule"),size=observationCount,replace=T)
head(education)
df<-data.frame(ids,sex,age,size,income,education)
head(df,minObservations)
df$sex.f<-as.factor(df$sex)
dim(df)
head(df)
# df$income.f<-as.factor(df$income,c(0,90000,130000,Inf))
# df
```

Es waere sehr verwunderlich, wenn es in diesem Dataframe zwei genau gleiche Datensaetze haette.
```{r}
any(duplicated(df))
```

Berechnen des Durchschnittalters pro Geschlecht:
```{r}
tapply(df$age, df$sex, mean, na.rm=T)
```

Aus dem Dataframe der **`r nrow(df)`** Datensaetze hat, die ersten **`r minObservations`** Datensaetze nehmen und daraus einen neuen erzeugen.
```{r}
sampleDf<-df[1:minObservations,]
sampleDf
```

Einen Dataframe aufsplitten, hier z.B. nach Geschlecht:
```{r}
part.female<- split(sampleDf, sampleDf$sex)
part.female
```

Datensaetze mit gewissen Kriterien kann man auf verschiedene Arten auslesen, z.B. mit **which**, oder mit dem Befehl **subset**.
```{r}
sampleDf[which(sampleDf$income>=140000),]
subset(sampleDf, sampleDf$income>=140000)
table(sampleDf$sex, sampleDf$education)
```

Eine Haeufigkeitstabelle die aussagt, wieviele Frauen oder Maenner dieselbe Ausbildungsstufe haben. Dies kann mit den Befehlen **table** und **xtabs** bewerkstelligt werden.
```{r}
table(sampleDf$sex,sampleDf$education)
xtabs(~sex + education, data=sampleDf)
```

Der Data Frame wird in eine Matrix konvertiert und mit anderen Spalten- und Zeilennamen versehen. Man beachte den Unterschied der Matrix wenn sie mit dem Befehl as.matrix(), oder data.matrix() konvertiert wurde.
```{r}
columnNames<-c("ID","Geschl.","Alter","Groesse","Einkommen","Ausbildung", "Geschl.f")
rowNames<-NULL
for (id in sampleDf$ids) {
 rowNames <- c(rowNames, paste('Obs.', id, collapse = "," ))
}
asMatrix<-as.matrix(sampleDf)
dimnames(asMatrix) <- list(rowNames, columnNames)
asMatrix<-subset(asMatrix,select=-ID)
head(asMatrix, minObservations)
dataMatrix<-data.matrix(sampleDf)
dimnames(dataMatrix) <- list(rowNames, columnNames)
dataMatrix<-subset(dataMatrix, select=-ID)
head(dataMatrix, minObservations)
```

# Tag 3
Einige Plots und Histogramme auf dem originalen Dataframe. Da saemtliche Daten im Dataframe zufaellig erzeugt wurden, sehen die Grafiken und Kurven natuerlich auch willkuerlich und etwas chaotisch aus.

```{r ,echo=TRUE, fig.cap="Fig. 3.1 Histogramm mit Dichte (Normalverteilung)", fig.align="center"}
hist(df$age, prob=T)
lines(density(df$age), col="red")
```

```{r ,echo=TRUE, fig.cap="Fig. 3.2 Scatterplot Einkommen nach Alter", fig.align="center"}
plot(df$age, df$income, type="p", main="Scatterplot")
```

```{r ,echo=TRUE, fig.cap="Fig. 3.3 Scatterplot", fig.align="center"}
plot(df$income, main="Scatterplot")
```

```{r ,echo=TRUE, fig.cap="Fig. 3.4 Histogramm Income", fig.align="center"}
hist(df$income, main="Histogramm")
```

```{r ,echo=TRUE, fig.cap="Fig. 3.5 Boxplot nach Income", fig.align="center"}
boxplot(df$income, main="Boxplot")
```
Ein Boxplot beinhaltet fuenf Informationen. Der dicke Strich im Kasten ist der Median, der obere und untere Rand des Kastens zeigen die Quantile Q1 (25% der Werte sind kleiner als dieser Wert) und Q3 (25% der Werte sind groesser als dieser Wert) an, der unterste Strich ist das Minimum und der oberste Strich das Maximum

An sich ein simpler Plot der jedoch schoen anzuschauen ist und vorallem die Daten aus einem clever kombinierten Dataframe bezieht. Eine an dieser Stelle zentrale Funktion ist **rbind()** welche jeweils die Zeilen eines Dataframes in einen neuen (oder wieder den urspruenglichen) merged. Dieses Beispiel stammt von <http://rstudio-pubs-static.s3.amazonaws.com/18905_c8e7a77909704e90a4a38cd3e8bc30f9.html>

```{r}
iter <- 10000
p <- runif(iter)
coord <- matrix(c(0, 0), ncol = 1)
dfFeather <- rbind(data.frame(), t(coord))
for (i in 1:iter) {
    if (p[i] <= 0.05) {
        m <- matrix(c(0, 0, 0, 0.16), nrow = 2, ncol = 2)
        const <- matrix(c(0, 0), ncol = 1)
    } else if (p[i] > 0.05 && p[i] <= 0.86) {
        m <- matrix(c(0.85, -0.04, 0.04, 0.85), nrow = 2, ncol = 2)
        const <- matrix(c(0, 1.6), ncol = 1)
    } else if (p[i] > 0.86 && p[i] <= 0.93) {
        m <- matrix(c(0.2, 0.23, -0.26, 0.22), nrow = 2, ncol = 2)
        const <- matrix(c(0, 1.6), ncol = 1)

    } else {
        m <- matrix(c(-0.15, 0.26, 0.28, 0.24), nrow = 2, ncol = 2)
        const <- matrix(c(0, 0.44), ncol = 1)
    }
    coord <- m %*% coord + const
    dfFeather <- rbind(dfFeather, t(coord))
}
plot(x = dfFeather[, 2], y = dfFeather[, 1], plt = c(0, 10, -5, 5), cex = 0.1, asp = 1)
```

# Tag 4
Im weiteren werden nicht mehr alle R Code Snippets im Report ersichtlich sein (echo=FALSE). Das vollstaendige Markdown mit R-Code ist im Anhang ersichtlich.

## Hypothesen
Hypothesen dienen der **Management Beratung**, oder sie kommen sogar aus dem Management.

* Am Anfang steht die **Diagnose**. Das Fachthema muss verstanden, das Problem genau identifiziert und es muss klar sein welche Daten benoetigt werden.
* Nun kann eine **Hypothese** aufgestellt werden. Das Problem kann als hypothetische Ursache-Wirkung formuliert werden.
* **Analyse** erstellen.Ursache-Wirkung anahnd von einem Datenmodell, Fragebogen erstellen. Entweder existieren bereits brauchbare Daten die gesammelt werden muessen, oder sie muessen erhoben werden.
* Nun kann ein **Entscheid** formuliert werden. Besagt der Test, dass die Hypothese signifikant ist, koennen Handlungsoptionen agbeleitet werden und die Wirkung der Massnahmen (theoretisch) gemessen werden.
Die **Qualitaet** des Entscheids haengt von drei Aspekten ab:
    + **Repraesentativitaet**: Analyse wurde mit der korrekten Zielgruppe durchgefuehrt. Je groesser die Zielgruppe, desto besser
    + **Signifikanz**: Das Resultat ist nicht zufaellig und ist bei einer zweiten Analyse in etwa gleich. Auch hier, je groesser n desto signifikanter
    + **Relevanz**: Das Resultat der Analyse kann einen Entscheid untermauern und es koennen Prognosen gemacht werden.

\
Um etwas mit Daten spielen zu koennen, wird ein Dataframe d mit Zufallszahlen generiert (Copy Paste aus dem Skript).
\
Im folgenden Plot ist der Lohn nach Alter fuer die Branchen Finance, Industry und State und die Laender England, Schweiz und die USA aufgezeigt. Die Geschlechter werden mit unterschiedlichen Formen der Punkte unterschieden.

\
In Fig. 4.1 sind folgende Hypothesen ersichtlich:

* Die Loehne unterscheiden sich in den Laendern und Branchen
* Frauen verdienen mehr als Maenner
* In der CH- und US-Industrie verdienen Maenner weniger je aelter sie werden, in allen anderen Branchen ist es umgekehrt.
```{r echo=FALSE}
set.seed(145) # generiert jedesmal die gleichen Werte
n <- 500 # n ist die Anzahl Beobachtungen
Land <- sample(c("CH", "USA", "GB"), n, replace = TRUE, prob = c(0.6, 0.25, 0.15))
Geschl <- rep("X", n) # Dummy "X"
Branche <- rep("X", n) # Dummy "X"
Lohn <- rep(1, n) # Dummy "1"
Alter <- rep(1, n) # Dummy "1"
d <- data.frame(Land, Geschl, Branche, Alter, Lohn) # erstellt DataFrame

######## Datengenerierung per Land #########################
######### Daten f?r CH ###################
d$Geschl <- ifelse(d$Land == "CH", sample(c("M", "F"), n, replace = TRUE, prob = c(0.65, 0.35)),d$Geschl)
d$Branche <- ifelse(d$Land == "CH", sample(c("Fin", "Ind", "Sta"), n, replace = TRUE, prob = c(0.4,0.35,0.15)),d$Branche)
d$Alter <- ifelse(d$Land == "CH", 20+30*rbeta(n, 5, 5), d$Alter)
##### CH-M?nner
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Fin" & d$Geschl=="M",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Ind" & d$Geschl=="M", -(1+runif(n))*d$Alter+120,d$Lohn)
#d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Sta" & d$Geschl=="M",(1.5+runif(n))*d$Alter-20,d$Lohn)
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Sta" & d$Geschl=="M",10+runif(n)*d$Alter,d$Lohn)
##### CH-Frauen
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Fin" & d$Geschl=="F",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Ind" & d$Geschl=="F",(2+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "CH" & d$Branche == "Sta" & d$Geschl=="F",(1.5+runif(n))*d$Alter,d$Lohn)

######### Daten f?r USA ###################
d$Geschl <- ifelse(d$Land == "USA",sample(c("M","F"), n, replace = TRUE, prob = c(0.45,0.55)),d$Geschl)
d$Branche <- ifelse(d$Land == "USA", sample(c("Fin","Ind","Sta"), n, replace = TRUE, prob = c(0.3,0.3,0.4)),d$Branche)

##### USA-M?nner
d$Alter <- ifelse(d$Land == "USA" & d$Geschl == "M",10+30*rbeta(n,5,5),d$Alter)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Fin" & d$Geschl=="M",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Ind" & d$Geschl=="M", -(1+runif(n))*d$Alter+100,d$Lohn)
#d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Sta" & d$Geschl=="M",(1.5+runif(n))*d$Alter-10,d$Lohn)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Sta" & d$Geschl=="M",(0.5+runif(n))*d$Alter,d$Lohn)
##### USA-Frauen
d$Alter <- ifelse(d$Land == "USA" & d$Geschl == "F",25+40*rbeta(n,5,5),d$Alter)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Fin" & d$Geschl=="F",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Ind" & d$Geschl=="F",(1.2+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "USA" & d$Branche == "Sta" & d$Geschl=="F",(1.5+runif(n))*d$Alter,d$Lohn)

######### Daten f?r GB ###################
d$Geschl <- ifelse(d$Land == "GB",sample(c("M","F"), n, replace = TRUE, prob = c(0.5,0.5)),d$Geschl)
d$Branche <- ifelse(d$Land == "GB", sample(c("Fin","Ind","Sta"), n, replace = TRUE, prob = c(0.35,0.35,0.3)),d$Branche)
d$Alter <- ifelse(d$Land == "GB",20+20*rbeta(n,5,5),d$Alter)
##### GB-M?nner
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Fin" & d$Geschl=="M",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Ind" & d$Geschl=="M", -(1+runif(n))*d$Alter+100,d$Lohn)
#d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Sta" & d$Geschl=="M",(1.5+runif(n))*d$Alter-10,d$Lohn)
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Sta" & d$Geschl=="M",(0.5+runif(n))*d$Alter,d$Lohn)
##### GB-Frauen
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Fin" & d$Geschl=="F",(1+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Ind" & d$Geschl=="F",(1.2+runif(n))*d$Alter,d$Lohn)
d$Lohn <- ifelse(d$Land == "GB" & d$Branche == "Sta" & d$Geschl=="F",(1.5+runif(n))*d$Alter,d$Lohn)
```
\
```{r fig.cap="4.1 Verteilung", fig.align="center"}
qplot(Alter, Lohn, data=d, shape=Geschl, color=Geschl,
   facets=Land~Branche, size=I(1),
   main="Lohn nach Alter pro Land und Branche mit Geschlechteraufteilung",
   xlab="Alter", ylab="Lohn")
```
```{r fig.cap="4.2 Density", fig.align="center"}
qplot(Lohn, data=d, geom="density", fill=Land, alpha=I(.5),
   main="Verteilung des Lohns", xlab="Lohn in CHF",
   ylab="Dichte")
```

## Tests

### T-Test / Anova
```{r}
CHAndGBSalaries<-subset(d, d$Land=="GB" | d$Land=="CH")
myData<-data.frame(CHAndGBSalaries$Land, CHAndGBSalaries$Lohn)
myData<-droplevels(myData) # loescht den dritten Level da R den Level "USA" preserved. Fuer den T-Test ist dies nicht zwingend erforderlich
t.test(CHAndGBSalaries$Lohn ~ CHAndGBSalaries$Land, data=CHAndGBSalaries, var.equal=TRUE)
```

Der p-value ist im Promillebereich. Somit ist das Resultat signifikant, was in diesem Falle bedeutet, dass sich die Loehne klar nach Land unterscheiden.
\
Ein Anova-Test mit nur zwei Faktoren entspricht dem T-Test. Man kann dies an den identischen p-values erkennen
```{r}
fit<-aov(Lohn ~ Land, data=CHAndGBSalaries)
summary(fit)
```
Werden nun noch die US Daten mitrein gemischelt, ist das Resultat nicht mehr signifikant da die US und CH Loehne recht aehnlich sind.
```{r}
fit<-aov(Lohn ~ Land, data=myData)
summary(fit)
```

### Chisq-Test
Der XQuadrat Test wird oft verwendet, wenn n unabhaengige Beobachtungen in m verschiedene Kategorien fallen. z.B. Verkehrsunfaelle pro Wochentag gemessen ueber ein Jahr.
```{r}
verkehrsunfaelleProWochentag<-c(80,99,78,89,82,79,53)
chisq.test(verkehrsunfaelleProWochentag)
```
Da der p-value relativ klein ist, kann die Nullhypothese (Die Haeufigkeit der Verkehrsunfaelle pro Wochentag unterscheidet sich NICHT) verworfen werden, es gibt also Unterschiede zwischen den Wochentagen

### Prop-Test
Der Probability Test kann gut bei Umfragen/Experimenten verwendet werden. Man laesst z.B. 200 Personen Bier mit und ohne Alkohol trinken und erfasst wie oft sie richtig getippt haben. In diesem Beispiel wird angenommen, dass 145 Personen richtig lagen.
```{r}
prop.test(x=145,n=200,p=0.5,alt="greater")
```
Das Resultat zeigt, dass sich alkoholfreies und alkoholhaltiges Bier im Geschmack unterscheiden (alternativ Hypothese).

### Wilcox-Test
Der Mann-Whitney-Wilcoxon Test wird angewendet wenn zwei unabhaengige Gruppen von Beobachtungen vorliegen. Die Nullhypothese ist, dass es in den Daten von mtcars zwischen Autos mit automatischem (am = automatic) und geschaltetem Getriebe keinen Unterschied im Verbrauch (mpg = miles per gallon) gibt.
```{r}
wilcox.test(mpg ~ am, data=mtcars)
```
```{r fig.cap="4.3 Verteilung der mpg", fig.align="center"}
qplot(mpg, data=mtcars, geom="density", fill=as.factor(am), alpha=I(.5),
   xlab="Meilen pro Gallone",
   ylab="Dichte")

fit <- aov(mpg ~ cyl, data=mtcars)
summary(fit)

```
In Fig 4.3 kann man gut sehen, dass Autos mit Handschaltung (1) tendenziell weiter kommen mit einer Gallone Treibstoff.

# Tag 5
## Regressionsmodelle
Die **Korrelation** von -0.852 zwischen 'Miles per Gallon' und 'Cylinder' ist nicht gerade gross, fuer dieses Beispiel jedoch ausreichend.
```{r}
carsData<-mtcars
cor.test(carsData$cyl, carsData$mpg)
```
Je naeher der **Adjusted R-Squared** Wert bei Eins ist, desto besser die Guete des Modells. In Fig. 5.1 ist der schlechte R-Squared Wert und auch die nicht gerade berauschende Korrelation zu sehen, man kann jedoch trotzdem erkennen, dass Autos mit vielen Zylindern weniger weit kommen mit einer Gallone Benzin.
\
Das **Regressionsmodell** lautet somit: mpg = 37.88 - 2.88 * cyl
```{r fig.cap="5.1 Lineare Regression Verbrauch und Anzahl Zylinder", fig.align="center"}
fit<-lm(carsData$mpg ~ carsData$cyl)
summary(fit)
plot(carsData$cyl, carsData$mpg)
abline(fit,col="red")
```
Hat man mehr als zwei Praediktoren, laesst sich die Regressionsgerade nicht mehr 2-dimensional darstellen. Dies laesst sich jedoch in einem 3D Diagramm darstellen (mpg = Miles per Gallon, wt = Weight, disp = Displacement).
```{r testgl, webgl=TRUE}
plot3d(x = carsData$wt, y = carsData$disp, z = carsData$mpg, col=rainbow(1000))
```

<!-- # Anhang -->
<!-- ## RMarkdown code -->
<!-- ```{r comment=''} -->
<!-- cat(readLines('Conclusions.Rmd'), sep = '\n') -->
<!-- ``` -->
<!-- ## Shiny app code -->
<!-- ```{r comment=''} -->
<!-- cat(readLines('D:/Projects/HWZ/app.R'), sep = '\n') -->
<!-- ``` -->
